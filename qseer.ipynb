{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGIK9O97vZRG",
        "outputId": "44d0ecdd-89f4-40cf-8af6-a58d20812c26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m103.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "torchversion = torch.__version__\n",
        "\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-{torchversion}.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-{torchversion}.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")\n",
        "%cd /content/gdrive/MyDrive/QSeer/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkOtpaCIvro7",
        "outputId": "5e1d6ce4-8b39-43c7-ced7-b8b31d8d473d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/MyDrive/QSeer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.data import Data, InMemoryDataset\n",
        "import torch\n",
        "\n",
        "def interleave_arrays(arr1, arr2):\n",
        "  return np.ravel(np.column_stack((arr1, arr2)))\n",
        "\n",
        "class GraphDataset(InMemoryDataset):\n",
        "  def __init__(self, root, file_name=None, transform=None, pre_transform=None, pre_filter=None):\n",
        "    self.filename = file_name\n",
        "    super(GraphDataset, self).__init__(root, transform, pre_transform, pre_filter)\n",
        "    self.load(self.processed_paths[0])\n",
        "\n",
        "  @property\n",
        "  def raw_file_names(self):\n",
        "    return [self.filename]\n",
        "\n",
        "  @property\n",
        "  def processed_file_names(self):\n",
        "    return [self.filename + \".pt\"]\n",
        "\n",
        "  def process(self):\n",
        "    data_list = []\n",
        "    my_list = joblib.load(self.filename)\n",
        "    index = 0\n",
        "    for item in my_list:\n",
        "      graph = item[\"graph\"]\n",
        "      gamma = np.array(item[\"gamma\"], dtype=np.float32)\n",
        "      beta =  np.array(item[\"beta\"], dtype=np.float32)\n",
        "      layer = np.array(np.shape(gamma)[0], dtype=np.int32)\n",
        "      n_values = np.max(4)\n",
        "      layer = np.eye(n_values)[layer-1]\n",
        "      label = interleave_arrays(gamma, beta)\n",
        "      label = np.pad(label, (0, 8 - np.shape(label)[0]), mode='constant', constant_values=0)\n",
        "\n",
        "      source_list = None\n",
        "      target_list = None\n",
        "      for edge in graph.edges():\n",
        "        if source_list is None:\n",
        "          source_list = np.array(edge[0])\n",
        "          target_list = np.array(edge[1])\n",
        "        else:\n",
        "          source_list = np.append(source_list, edge[0])\n",
        "          target_list = np.append(target_list, edge[1])\n",
        "\n",
        "      edge_index = torch.tensor([source_list, target_list], dtype=torch.int64)\n",
        "      edge_attr = torch.tensor([[i] for i in range(len(graph.edges()))], dtype=torch.float32)\n",
        "      x = torch.tensor([[i] for i in range(graph.number_of_nodes())], dtype=torch.float32)\n",
        "      y = torch.tensor(label, dtype=torch.float32).flatten()\n",
        "      y = torch.unsqueeze(y, 0)\n",
        "      layer = torch.tensor(layer, dtype=torch.float32).flatten()\n",
        "      layer = torch.unsqueeze(layer, 0)\n",
        "      data = Data(edge_index=edge_index, edge_attr=edge_attr, x=x, y=y, layer=layer)\n",
        "      data_list.append(data)\n",
        "\n",
        "    self.save(data_list, self.processed_paths[0])\n",
        "\n",
        "train_dataset = GraphDataset(root='./data/', file_name='./data/graph_train.pkl')\n",
        "test_dataset = GraphDataset(root='./data/', file_name='./data/graph_test.pkl')\n",
        "valid_dataset = GraphDataset(root='./data/', file_name='./data/graph_valid.pkl')\n",
        "\n",
        "print(train_dataset.num_node_features)\n",
        "print(train_dataset.num_classes)\n",
        "print(train_dataset[0].layer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9tgxGRRwCe_",
        "outputId": "66cfee19-843b-4203-c104-ab27a0fd79d7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "8\n",
            "tensor([[1., 0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.data import Data, InMemoryDataset\n",
        "import torch\n",
        "\n",
        "def interleave_arrays(arr1, arr2):\n",
        "  return np.ravel(np.column_stack((arr1, arr2)))\n",
        "\n",
        "class GraphWDataset(InMemoryDataset):\n",
        "  def __init__(self, root, file_name=None, transform=None, pre_transform=None, pre_filter=None):\n",
        "    self.filename = file_name\n",
        "    super(GraphWDataset, self).__init__(root, transform, pre_transform, pre_filter)\n",
        "    self.load(self.processed_paths[0])\n",
        "\n",
        "  @property\n",
        "  def raw_file_names(self):\n",
        "    return [self.filename]\n",
        "\n",
        "  @property\n",
        "  def processed_file_names(self):\n",
        "    return [self.filename + \".pt\"]\n",
        "\n",
        "  def process(self):\n",
        "    data_list = []\n",
        "    my_list = joblib.load(self.filename)\n",
        "    index = 0\n",
        "    for item in my_list:\n",
        "      source_list = item[\"slist\"]\n",
        "      target_list = item[\"tlist\"]\n",
        "\n",
        "      gamma = np.array(item[\"gamma\"], dtype=np.float32)\n",
        "      beta =  np.array(item[\"beta\"], dtype=np.float32)\n",
        "      layer = np.array(np.shape(gamma)[0], dtype=np.int32)\n",
        "      n_values = np.max(4)\n",
        "      layer = np.eye(n_values)[layer-1]\n",
        "      label = interleave_arrays(gamma, beta)\n",
        "      label = np.pad(label, (0, 8 - np.shape(label)[0]), mode='constant', constant_values=0)\n",
        "\n",
        "      edge_index = torch.tensor([source_list, target_list], dtype=torch.int64)\n",
        "      edge_attr = torch.tensor([[item[\"wlist\"][i]] for i in range(len(item[\"wlist\"]))], dtype=torch.float32)\n",
        "      num_nodes = torch.max(edge_index).item() + 1\n",
        "      x = torch.tensor([[i] for i in range(num_nodes)], dtype=torch.float32)\n",
        "      y = torch.tensor(label, dtype=torch.float32).flatten()\n",
        "      y = torch.unsqueeze(y, 0)\n",
        "      layer = torch.tensor(layer, dtype=torch.float32).flatten()\n",
        "      layer = torch.unsqueeze(layer, 0)\n",
        "      data = Data(edge_index=edge_index, edge_attr=edge_attr, x=x, y=y, layer=layer)\n",
        "      data_list.append(data)\n",
        "\n",
        "    self.save(data_list, self.processed_paths[0])\n",
        "\n",
        "\n",
        "train_dataset = GraphWDataset(root='./data/', file_name='./data/weighted_graph_train.pkl')\n",
        "test_dataset = GraphWDataset(root='./data/', file_name='./data/weighted_graph_test.pkl')\n",
        "valid_dataset = GraphWDataset(root='./data/', file_name='./data/weighted_graph_valid.pkl')\n",
        "\n",
        "print(train_dataset.num_node_features)\n",
        "print(train_dataset.num_classes)\n",
        "print(train_dataset[0].layer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKDaU9rtxFAV",
        "outputId": "ce025531-b1a1-43ce-8cdc-ac6e7b8a45c4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "8\n",
            "tensor([[1., 0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.data import Data, InMemoryDataset\n",
        "import torch\n",
        "\n",
        "def interleave_arrays(arr1, arr2):\n",
        "  return np.ravel(np.column_stack((arr1, arr2)))\n",
        "\n",
        "class GraphGDataset(InMemoryDataset):\n",
        "  def __init__(self, root, file_name=None, num_layer = 4, transform=None, pre_transform=None, pre_filter=None):\n",
        "    self.filename = file_name\n",
        "    self.num_layer = num_layer\n",
        "    super(GraphGDataset, self).__init__(root, transform, pre_transform, pre_filter)\n",
        "    self.load(self.processed_paths[0])\n",
        "\n",
        "  @property\n",
        "  def raw_file_names(self):\n",
        "    return [self.filename]\n",
        "\n",
        "  @property\n",
        "  def processed_file_names(self):\n",
        "    return [self.filename + \"_\" + str(self.num_layer) + \"_.pt\"]\n",
        "\n",
        "  def process(self):\n",
        "    data_list = []\n",
        "    graph_list = joblib.load(self.filename)\n",
        "    index = 0\n",
        "    for graph in graph_list:\n",
        "      source_list = None\n",
        "      target_list = None\n",
        "      edge_list = graph.edges()\n",
        "      for edge in edge_list:\n",
        "        if source_list is None:\n",
        "          source_list = np.array([edge[0]])\n",
        "          target_list = np.array([edge[1]])\n",
        "        else:\n",
        "          source_list = np.append(source_list, edge[0])\n",
        "          target_list = np.append(target_list, edge[1])\n",
        "\n",
        "      layer = np.array(self.num_layer, dtype=np.int32)\n",
        "      n_values = np.max(4)\n",
        "      layer = np.eye(n_values)[layer-1]\n",
        "\n",
        "      edge_index = torch.tensor([source_list, target_list], dtype=torch.int64)\n",
        "      edge_attr = torch.tensor([[i] for i in range(len(edge_list))], dtype=torch.float32)\n",
        "\n",
        "      x = torch.tensor([[i] for i in range(graph.number_of_nodes())], dtype=torch.float32)\n",
        "      layer = torch.tensor(layer, dtype=torch.float32).flatten()\n",
        "      layer = torch.unsqueeze(layer, 0)\n",
        "      data = Data(edge_index=edge_index, edge_attr=edge_attr, x=x, y=None, layer=layer)\n",
        "      data_list.append(data)\n",
        "\n",
        "    self.save(data_list, self.processed_paths[0])"
      ],
      "metadata": {
        "id": "ujxIWSiJ_oHw"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import Linear, Sequential, ReLU#, Dropout, BatchNorm1d\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv, GATConv, GINConv\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "\n",
        "class DGNN(torch.nn.Module):\n",
        "  def __init__(self, n_x, n_y, dim_h):\n",
        "    super(DGNN, self).__init__()\n",
        "    hidden_channels_gcn = dim_h * 2\n",
        "    hidden_channels_gat = hidden_channels_gcn * 2\n",
        "    hidden_channels_gin = hidden_channels_gat * 2\n",
        "\n",
        "    # Initialize the first GCNConv layer in the forward method\n",
        "    self.conv1 = GCNConv(n_x, hidden_channels_gcn)\n",
        "    self.hidden_channels_gcn = hidden_channels_gcn\n",
        "    self.conv2 = GCNConv(hidden_channels_gcn, hidden_channels_gcn)\n",
        "    self.gat_conv1 = GATConv(hidden_channels_gcn, hidden_channels_gat)\n",
        "    self.gat_conv2 = GATConv(hidden_channels_gat, hidden_channels_gat)\n",
        "\n",
        "    mlp = torch.nn.Sequential(\n",
        "        Linear(hidden_channels_gat, hidden_channels_gin),\n",
        "        ReLU(),\n",
        "        Linear(hidden_channels_gin, hidden_channels_gin)\n",
        "    )\n",
        "    self.gin_conv1 = GINConv(mlp)\n",
        "    self.out = Linear(hidden_channels_gin + 4, hidden_channels_gin)\n",
        "    self.out2 = Linear(hidden_channels_gin, n_y)\n",
        "\n",
        "  def forward(self, x, edge_index, edge_weight, layer, batch):\n",
        "    x = F.relu(self.conv1(x = x, edge_index = edge_index, edge_weight = edge_weight))\n",
        "    #print(x)\n",
        "    x = F.relu(self.conv2(x = x, edge_index = edge_index, edge_weight = edge_weight))\n",
        "    x = F.relu(self.gat_conv1(x = x, edge_index = edge_index, edge_attr = edge_weight))\n",
        "    x = F.relu(self.gat_conv2(x = x, edge_index = edge_index, edge_attr = edge_weight))\n",
        "    x = F.relu(self.gin_conv1(x = x, edge_index = edge_index))\n",
        "    x = global_mean_pool(x, batch)\n",
        "    #print(x.shape)\n",
        "    #print(layer.shape)\n",
        "    x = torch.cat([x, layer], dim=1)\n",
        "    x = self.out(x)\n",
        "    x = self.out2(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "kEbkS5-GxEOP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "train_dataset = GraphDataset(root='./data/', file_name='./data/graph_train.pkl')\n",
        "test_dataset = GraphDataset(root='./data/', file_name='./data/graph_test.pkl')\n",
        "valid_dataset = GraphDataset(root='./data/', file_name='./data/graph_valid.pkl')\n",
        "\n",
        "model = DGNN(n_x=train_dataset.num_node_features, n_y=train_dataset.num_classes, dim_h=256).to(\"cuda\")\n",
        "loss_fn = nn.MSELoss()  # mean square error\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
        "\n",
        "n_epochs = 20\n",
        "batch_size = 4096\n",
        "myloader = DataLoader(train_dataset, batch_size=batch_size)\n",
        "youloader = DataLoader(valid_dataset, batch_size=batch_size)\n",
        "testloader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "save_path = './best_model.pth'\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  model.train()\n",
        "  mse_list = []\n",
        "  for data in myloader:\n",
        "    data = data.to(\"cuda\")\n",
        "    out = model(data.x, data.edge_index, data.edge_attr, data.layer, data.batch)\n",
        "    loss = loss_fn(out, data.y)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    mse_list.append(float(loss))\n",
        "  train_mse = sum(mse_list) / len(mse_list)\n",
        "  print(f\"model epoch {epoch} training mse {train_mse:.4f}\")\n",
        "\n",
        "  model.eval()\n",
        "  mse_list = []\n",
        "  for data in youloader:\n",
        "    data = data.to(\"cuda\")\n",
        "    out = model(data.x, data.edge_index, data.edge_attr, data.layer, data.batch)\n",
        "    loss = loss_fn(out, data.y)\n",
        "    mse_list.append(float(loss))\n",
        "  valid_mse = sum(mse_list) / len(mse_list)\n",
        "  print(f\"model epoch {epoch} valid mse {valid_mse:.4f}\")\n",
        "\n",
        "  if valid_mse < best_val_loss:\n",
        "    best_val_loss = valid_mse\n",
        "    torch.save(model.state_dict(), save_path)\n",
        "    print(f'Saved best model with validation loss: {best_val_loss:.4f}')\n",
        "\n",
        "  scheduler.step()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nb1Xe77dyIDT",
        "outputId": "53a1a9ea-46f7-4f80-8fb5-d8ff361de596"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model epoch 0 training mse 43119.5338\n",
            "model epoch 0 valid mse 0.0027\n",
            "Saved best model with validation loss: 0.0027\n",
            "model epoch 1 training mse 0.0018\n",
            "model epoch 1 valid mse 0.0015\n",
            "Saved best model with validation loss: 0.0015\n",
            "model epoch 2 training mse 0.0013\n",
            "model epoch 2 valid mse 0.0011\n",
            "Saved best model with validation loss: 0.0011\n",
            "model epoch 3 training mse 0.0012\n",
            "model epoch 3 valid mse 0.0008\n",
            "Saved best model with validation loss: 0.0008\n",
            "model epoch 4 training mse 0.0009\n",
            "model epoch 4 valid mse 0.0007\n",
            "Saved best model with validation loss: 0.0007\n",
            "model epoch 5 training mse 0.0010\n",
            "model epoch 5 valid mse 0.0005\n",
            "Saved best model with validation loss: 0.0005\n",
            "model epoch 6 training mse 0.0009\n",
            "model epoch 6 valid mse 0.0005\n",
            "Saved best model with validation loss: 0.0005\n",
            "model epoch 7 training mse 0.0008\n",
            "model epoch 7 valid mse 0.0004\n",
            "Saved best model with validation loss: 0.0004\n",
            "model epoch 8 training mse 0.0007\n",
            "model epoch 8 valid mse 0.0004\n",
            "Saved best model with validation loss: 0.0004\n",
            "model epoch 9 training mse 0.0008\n",
            "model epoch 9 valid mse 0.0007\n",
            "model epoch 10 training mse 0.0009\n",
            "model epoch 10 valid mse 0.0005\n",
            "model epoch 11 training mse 0.0009\n",
            "model epoch 11 valid mse 0.0004\n",
            "Saved best model with validation loss: 0.0004\n",
            "model epoch 12 training mse 0.0010\n",
            "model epoch 12 valid mse 0.0008\n",
            "model epoch 13 training mse 0.0007\n",
            "model epoch 13 valid mse 0.0004\n",
            "Saved best model with validation loss: 0.0004\n",
            "model epoch 14 training mse 0.0012\n",
            "model epoch 14 valid mse 0.0004\n",
            "Saved best model with validation loss: 0.0004\n",
            "model epoch 15 training mse 0.0008\n",
            "model epoch 15 valid mse 0.0004\n",
            "model epoch 16 training mse 0.0009\n",
            "model epoch 16 valid mse 0.0003\n",
            "Saved best model with validation loss: 0.0003\n",
            "model epoch 17 training mse 0.0010\n",
            "model epoch 17 valid mse 0.0013\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ggk3hVjZ1mrJ",
        "outputId": "59e261ff-27e7-4f1c-cb42-5e70b34e5c5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model epoch 0 training mse 31255.4957\n",
            "model epoch 0 valid mse 0.0127\n",
            "Saved best model with validation loss: 0.0127\n",
            "model epoch 1 training mse 0.0036\n",
            "model epoch 1 valid mse 0.0023\n",
            "Saved best model with validation loss: 0.0023\n",
            "model epoch 2 training mse 0.0020\n",
            "model epoch 2 valid mse 0.0018\n",
            "Saved best model with validation loss: 0.0018\n",
            "model epoch 3 training mse 0.0015\n",
            "model epoch 3 valid mse 0.0013\n",
            "Saved best model with validation loss: 0.0013\n",
            "model epoch 4 training mse 0.0013\n",
            "model epoch 4 valid mse 0.0010\n",
            "Saved best model with validation loss: 0.0010\n",
            "model epoch 5 training mse 0.0010\n",
            "model epoch 5 valid mse 0.0008\n",
            "Saved best model with validation loss: 0.0008\n",
            "model epoch 6 training mse 0.0009\n",
            "model epoch 6 valid mse 0.0006\n",
            "Saved best model with validation loss: 0.0006\n",
            "model epoch 7 training mse 0.0008\n",
            "model epoch 7 valid mse 0.0006\n",
            "Saved best model with validation loss: 0.0006\n",
            "model epoch 8 training mse 0.0006\n",
            "model epoch 8 valid mse 0.0004\n",
            "Saved best model with validation loss: 0.0004\n",
            "model epoch 9 training mse 0.0012\n",
            "model epoch 9 valid mse 0.0004\n",
            "Saved best model with validation loss: 0.0004\n",
            "model epoch 10 training mse 0.0004\n",
            "model epoch 10 valid mse 0.0004\n",
            "Saved best model with validation loss: 0.0004\n",
            "model epoch 11 training mse 0.0004\n",
            "model epoch 11 valid mse 0.0003\n",
            "Saved best model with validation loss: 0.0003\n",
            "model epoch 12 training mse 0.0004\n",
            "model epoch 12 valid mse 0.0004\n",
            "model epoch 13 training mse 0.0006\n",
            "model epoch 13 valid mse 0.0005\n",
            "model epoch 14 training mse 0.0006\n",
            "model epoch 14 valid mse 0.0004\n",
            "model epoch 15 training mse 0.0005\n",
            "model epoch 15 valid mse 0.0005\n",
            "model epoch 16 training mse 0.0005\n",
            "model epoch 16 valid mse 0.0003\n",
            "model epoch 17 training mse 0.0006\n",
            "model epoch 17 valid mse 0.0003\n",
            "Saved best model with validation loss: 0.0003\n",
            "model epoch 18 training mse 0.0006\n",
            "model epoch 18 valid mse 0.0004\n",
            "model epoch 19 training mse 0.0005\n",
            "model epoch 19 valid mse 0.0005\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "train_dataset = GraphWDataset(root='./data/', file_name='./data/weighted_graph_train.pkl')\n",
        "test_dataset = GraphWDataset(root='./data/', file_name='./data/weighted_graph_test.pkl')\n",
        "valid_dataset = GraphWDataset(root='./data/', file_name='./data/weighted_graph_valid.pkl')\n",
        "\n",
        "model = DGNN(n_x=train_dataset.num_node_features, n_y=train_dataset.num_classes, dim_h=256).to(\"cuda\")\n",
        "#model.load_state_dict(torch.load(save_path, weights_only=True))\n",
        "\n",
        "loss_fn = nn.MSELoss()  # mean square error\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
        "\n",
        "n_epochs = 20\n",
        "batch_size = 1024\n",
        "myloader = DataLoader(train_dataset, batch_size=batch_size)\n",
        "youloader = DataLoader(valid_dataset, batch_size=batch_size)\n",
        "testloader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "save_path = './best_weighted_model.pth'\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  model.train()\n",
        "  mse_list = []\n",
        "  for data in myloader:\n",
        "    data = data.to(\"cuda\")\n",
        "    out = model(data.x, data.edge_index, data.edge_attr, data.layer, data.batch)\n",
        "    loss = loss_fn(out, data.y)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    mse_list.append(float(loss))\n",
        "  train_mse = sum(mse_list) / len(mse_list)\n",
        "  print(f\"model epoch {epoch} training mse {train_mse:.4f}\")\n",
        "\n",
        "  model.eval()\n",
        "  mse_list = []\n",
        "  for data in youloader:\n",
        "    data = data.to(\"cuda\")\n",
        "    out = model(data.x, data.edge_index, data.edge_attr, data.layer, data.batch)\n",
        "    loss = loss_fn(out, data.y)\n",
        "    mse_list.append(float(loss))\n",
        "  valid_mse = sum(mse_list) / len(mse_list)\n",
        "  print(f\"model epoch {epoch} valid mse {valid_mse:.4f}\")\n",
        "\n",
        "  if valid_mse < best_val_loss:\n",
        "    best_val_loss = valid_mse\n",
        "    torch.save(model.state_dict(), save_path)\n",
        "    print(f'Saved best model with validation loss: {best_val_loss:.4f}')\n",
        "\n",
        "  scheduler.step()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import joblib\n",
        "\n",
        "save_path = './best_model.pth'\n",
        "test_dataset = GraphDataset(root='./data/', file_name='./data/graph_test.pkl')\n",
        "model = DGNN(n_x=test_dataset.num_node_features, n_y=test_dataset.num_classes, dim_h=256).to(\"cuda\")\n",
        "model.load_state_dict(torch.load(save_path, weights_only=True))\n",
        "model.eval()\n",
        "testloader = DataLoader(test_dataset, batch_size=4096)\n",
        "test_result = []\n",
        "for data in testloader:\n",
        "  data = data.to(\"cuda\")\n",
        "  out = model(data.x, data.edge_index, data.edge_attr, data.layer, data.batch)\n",
        "  test_result.append(out.cpu().detach().numpy())\n",
        "\n",
        "test_result = np.concatenate(test_result, axis=0)\n",
        "print(np.shape(test_result))\n",
        "joblib.dump(test_result, \"./test_result.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfADDu77-vRj",
        "outputId": "ab614c45-907d-4da4-fbc8-4817bf392cba"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(81958, 8)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['./test_result.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import joblib\n",
        "\n",
        "save_path = './best_weighted_model.pth'\n",
        "test_dataset = GraphWDataset(root='./data/', file_name='./data/weighted_graph_test.pkl')\n",
        "model = DGNN(n_x=test_dataset.num_node_features, n_y=test_dataset.num_classes, dim_h=256).to(\"cuda\")\n",
        "model.load_state_dict(torch.load(save_path, weights_only=True))\n",
        "model.eval()\n",
        "testloader = DataLoader(test_dataset, batch_size=4096)\n",
        "test_result = []\n",
        "for data in testloader:\n",
        "  data = data.to(\"cuda\")\n",
        "  out = model(data.x, data.edge_index, data.edge_attr, data.layer, data.batch)\n",
        "  test_result.append(out.cpu().detach().numpy())\n",
        "\n",
        "test_result = np.concatenate(test_result, axis=0)\n",
        "print(np.shape(test_result))\n",
        "joblib.dump(test_result, \"./test_result_weighted.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPWD7dc9-3mF",
        "outputId": "de163279-7b70-4ea5-cff8-47488914f7e8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9509, 8)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['./test_result_weighted.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import joblib\n",
        "from torch_geometric.data import Batch, Dataset\n",
        "\n",
        "save_path = './best_model.pth'\n",
        "test_dataset1 = GraphGDataset(root='./data/', file_name='./data/graph_unseen_test.pkl', num_layer=1)\n",
        "test_dataset2 = GraphGDataset(root='./data/', file_name='./data/graph_unseen_test.pkl', num_layer=2)\n",
        "test_dataset3 = GraphGDataset(root='./data/', file_name='./data/graph_unseen_test.pkl', num_layer=3)\n",
        "\n",
        "\n",
        "model = DGNN(n_x=1, n_y=8, dim_h=256).to(\"cuda\")\n",
        "model.load_state_dict(torch.load(save_path, weights_only=True))\n",
        "model.eval()\n",
        "\n",
        "testloader = DataLoader(test_dataset1, batch_size=250)\n",
        "\n",
        "print(len(testloader))\n",
        "\n",
        "test_result = []\n",
        "for data in testloader:\n",
        "  data = data.to(\"cuda\")\n",
        "  out = model(data.x, data.edge_index, data.edge_attr, data.layer, data.batch)\n",
        "  test_result.append(out.cpu().detach().numpy())\n",
        "test_result = np.concatenate(test_result, axis=0)\n",
        "print(np.shape(test_result))\n",
        "joblib.dump(test_result, f\"./unseen_result_1.pkl\")\n",
        "\n",
        "\n",
        "testloader = DataLoader(test_dataset2, batch_size=250)\n",
        "test_result = []\n",
        "for data in testloader:\n",
        "  data = data.to(\"cuda\")\n",
        "  out = model(data.x, data.edge_index, data.edge_attr, data.layer, data.batch)\n",
        "  test_result.append(out.cpu().detach().numpy())\n",
        "test_result = np.concatenate(test_result, axis=0)\n",
        "print(np.shape(test_result))\n",
        "joblib.dump(test_result, f\"./unseen_result_2.pkl\")\n",
        "\n",
        "testloader = DataLoader(test_dataset3, batch_size=250)\n",
        "test_result = []\n",
        "for data in testloader:\n",
        "  data = data.to(\"cuda\")\n",
        "  out = model(data.x, data.edge_index, data.edge_attr, data.layer, data.batch)\n",
        "  test_result.append(out.cpu().detach().numpy())\n",
        "test_result = np.concatenate(test_result, axis=0)\n",
        "print(np.shape(test_result))\n",
        "joblib.dump(test_result, f\"./unseen_result_3.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzVr0QHv_ZZ3",
        "outputId": "14c77b73-3abf-43f9-8faf-cfb135807753"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12\n",
            "(3000, 8)\n",
            "(3000, 8)\n",
            "(3000, 8)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['./unseen_result_3.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install tensorcircuit[tensorflow]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8gPYhB3AhVt",
        "outputId": "130636e5-548d-4e29-e6bf-75b74f943041"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorcircuit[tensorflow] in /usr/local/lib/python3.11/dist-packages (0.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from tensorcircuit[tensorflow]) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from tensorcircuit[tensorflow]) (1.15.3)\n",
            "Requirement already satisfied: tensornetwork-ng in /usr/local/lib/python3.11/dist-packages (from tensorcircuit[tensorflow]) (0.5.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from tensorcircuit[tensorflow]) (3.5)\n",
            "Requirement already satisfied: tensorflow<2.16 in /usr/local/lib/python3.11/dist-packages (from tensorcircuit[tensorflow]) (2.15.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16->tensorcircuit[tensorflow]) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16->tensorcircuit[tensorflow]) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16->tensorcircuit[tensorflow]) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16->tensorcircuit[tensorflow]) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16->tensorcircuit[tensorflow]) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16->tensorcircuit[tensorflow]) (3.14.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16->tensorcircuit[tensorflow]) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.3.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16->tensorcircuit[tensorflow]) (0.3.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16->tensorcircuit[tensorflow]) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16->tensorcircuit[tensorflow]) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16->tensorcircuit[tensorflow]) (4.25.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16->tensorcircuit[tensorflow]) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16->tensorcircuit[tensorflow]) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16->tensorcircuit[tensorflow]) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16->tensorcircuit[tensorflow]) (4.14.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16->tensorcircuit[tensorflow]) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16->tensorcircuit[tensorflow]) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16->tensorcircuit[tensorflow]) (1.73.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16->tensorcircuit[tensorflow]) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16->tensorcircuit[tensorflow]) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.16->tensorcircuit[tensorflow]) (2.15.0)\n",
            "Requirement already satisfied: graphviz>=0.11.1 in /usr/local/lib/python3.11/dist-packages (from tensornetwork-ng->tensorcircuit[tensorflow]) (0.21)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow<2.16->tensorcircuit[tensorflow]) (0.45.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16->tensorcircuit[tensorflow]) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16->tensorcircuit[tensorflow]) (1.2.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16->tensorcircuit[tensorflow]) (3.8.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16->tensorcircuit[tensorflow]) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16->tensorcircuit[tensorflow]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16->tensorcircuit[tensorflow]) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16->tensorcircuit[tensorflow]) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16->tensorcircuit[tensorflow]) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16->tensorcircuit[tensorflow]) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16->tensorcircuit[tensorflow]) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16->tensorcircuit[tensorflow]) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16->tensorcircuit[tensorflow]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16->tensorcircuit[tensorflow]) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16->tensorcircuit[tensorflow]) (2025.6.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<2.16->tensorcircuit[tensorflow]) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16->tensorcircuit[tensorflow]) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16->tensorcircuit[tensorflow]) (3.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorcircuit as tc\n",
        "import tensorflow as tf\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import random\n",
        "import joblib\n",
        "import torch\n",
        "\n",
        "def interleave_arrays(arr1, arr2):\n",
        "  return np.ravel(np.column_stack((arr1, arr2)))\n",
        "\n",
        "def beta_to_qaoa(beta):\n",
        "  return np.pi * np.array(beta, dtype=np.float32)\n",
        "\n",
        "def gamma_to_qaoa(gamma):\n",
        "  return -np.pi * np.array(gamma, dtype=np.float32) / 2\n",
        "\n",
        "def all_to_qaoa(param, layer):\n",
        "  pi0 = [np.pi] * layer\n",
        "  pi1 = [-np.pi/2] * layer\n",
        "  pi2 = interleave_arrays(pi1, pi0)\n",
        "  result = pi2 * param\n",
        "  return result.astype(np.float32)\n",
        "\n",
        "def beta_to_qaoa(beta):\n",
        "\n",
        "    return np.pi * np.array(beta, dtype=np.float32)\n",
        "\n",
        "\n",
        "K = tc.set_backend(\"tensorflow\")\n",
        "\n",
        "def QAOAansatz(params, g=None, L=4, return_circuit=False):\n",
        "  n = len(g.nodes)\n",
        "  c = tc.Circuit(n)\n",
        "  for i in range(n):\n",
        "    c.H(i)\n",
        "\n",
        "  #print(L)\n",
        "  for j in range(L):\n",
        "    for e in g.edges:\n",
        "      c.exp1(e[0], e[1], unitary=tc.gates._zz_matrix, theta=params[2 * j])\n",
        "\n",
        "    for i in range(n):\n",
        "        c.rx(i, theta=params[2 * j + 1])\n",
        "\n",
        "  if return_circuit is True:\n",
        "    return c\n",
        "\n",
        "  loss = 0.0\n",
        "  for e in g.edges:\n",
        "    loss += c.expectation_ps(z=[e[0], e[1]])\n",
        "\n",
        "  return K.real(loss)\n",
        "\n",
        "\n",
        "QAOA_vvag = K.jit(\n",
        "  tc.backend.vvag(QAOAansatz, argnums=0, vectorized_argnums=0), static_argnums=(1, 3)\n",
        ")\n",
        "opt = K.optimizer(tf.keras.optimizers.Adam(1e-3))\n",
        "\n",
        "graph_test = joblib.load(\"./data/graph_test.pkl\")\n",
        "result_test = joblib.load(\"./test_result.pkl\")\n",
        "\n",
        "index = 0\n",
        "better = 0\n",
        "best = 0\n",
        "\n",
        "for graph in graph_test:\n",
        "  g = graph[\"graph\"]\n",
        "  gamma = gamma_to_qaoa(graph[\"gamma\"])\n",
        "  beta =  beta_to_qaoa(graph[\"beta\"])\n",
        "  layer = np.shape(gamma)[0]\n",
        "  label = interleave_arrays(gamma, beta)\n",
        "  label = np.pad(label, (0, 8 - np.shape(label)[0]), mode='constant', constant_values=0)\n",
        "  label = np.expand_dims(label, axis=0)\n",
        "  para = result_test[index]\n",
        "  para = all_to_qaoa(para, 4)\n",
        "  para = np.expand_dims(para, axis=0)\n",
        "  p1 = K.implicit_randn(shape=[1, 8], stddev=0.1) # random\n",
        "  p2 = tf.convert_to_tensor(label) # ground truth\n",
        "  p3 = tf.convert_to_tensor(para) # predict\n",
        "  p = tf.concat([p1, p2, p3], 0)\n",
        "\n",
        "  LL = []\n",
        "  for num_circuit in range(3):\n",
        "    #c = QAOAansatz(params=p[num_circuit], g=prob, return_circuit=True)\n",
        "    loss = QAOAansatz(params=p[num_circuit], g=g, L=layer)\n",
        "    LL.append(K.numpy(loss))\n",
        "\n",
        "  if LL[2] < LL[0]:\n",
        "    better += 1\n",
        "\n",
        "  if LL[2] < LL[1]:\n",
        "    best += 1\n",
        "\n",
        "  index += 1\n",
        "  if index % 100 == 0:\n",
        "    print(index)\n",
        "    print(better)\n",
        "    print(best)\n",
        "\n",
        "\n",
        "print(index)\n",
        "print(better)\n",
        "print(best)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOP5LJ3TAj77",
        "outputId": "0c9c56ac-f144-49be-cafa-a7e8670370b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n",
            "100\n",
            "67\n"
          ]
        }
      ]
    }
  ]
}